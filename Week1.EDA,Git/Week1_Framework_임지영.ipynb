{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리는 개발자가 코드를 처음부터 작성하지 않고 작업을 수행하는데 사용할 수 있도록 미리 작성된 코드모임이다. 라이브러리는 일반적으로 특정 기능 집합에 초점을 맞추고 있으며, 그 예로는 행렬계산을 위한 Numpy 라이브러리, 데이터 조작과 분석을 위한 Pandas 라이브러리 등이 있다 . 반면, 프레임워크는 응용프로그램을 구축하기 위한 특정 구조와 규칙 집합을 제공하는 것이다. 프레임워크는 어플리케이션 전반의 아키텍쳐를 정의하고 어떻게 구성되어야 하는지에 대한 일련의 규칙과 지침을 제공한다. 웹개발을 위한 프레임워크 Django, UI제작을 위한 JavaScript 프레임워크 Vue등이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝과 딥러닝은 인공지능분야에서 밀접하게 연결된 분야이다. 머신러닝은 컴퓨터로 하여금 데이터로부터 학습할 수 있도록하는 방법론으로 지도학습, 비지도학습, 강화학습등이 있다. 이러한 방법론을 통해 분류, 회귀, 클러스터링등의 작업을 실행할 수 있다. 딥러닝은 머신러닝의 하위분야로 신경망을 통해 데이터로부터 학습하는 것에 초점을 맞추고 있다. 노드들이 연결된 수많은 레이러를 통해 복잡한 데이터를 학습할 수 있다. 딥러닝 알고리즘은 이미지 인식, 오디오 인식 및 자연어 처리와 같이 대량의 비정형데이터를 처리하는데 용이하다. 즉, 머신러닝은 데이터로부터 학습을 할 수 있는 방법을 의미하고, 딥러닝은 그 중에서 신경망구조를 활용하는 것을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # 코드를 CUDA-enabled GPU에서 실행할지, 로컬 cpu에서 실행할 지 결정\n",
    "torch.manual_seed(45) # 랜덤시드 설정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device + \" is available\") # 코드가 어디에서 실행되는 지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터셋 로드\n",
    "train_set = torchvision.datasets.MNIST( # 이미지 분류학습에 자주 사용되는 Handwritten digits 데이터셋\n",
    "    root = './data/MNIST', # 파일 저장 경로 지정\n",
    "    train = True, # 훈련에 사용할지 여부\n",
    "    download = True, # 다운로드 여부 \n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 숫자 이미지를 tensor로 변경\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 테스트데이터셋 로드\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch DataLoader 생성\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size) # 데이터셋을 지정한 batch_size로 iterate\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 형성\n",
    "class ConvNet(nn.Module): # nn.Module의 sub-class\n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__() # parent class의 init함수 실행\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # input channel 1, output channel 10이고, kernel size 5X5인 2d convolutional layer 형성\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False)  # Dropout 레이어 형성\n",
    "        self.mp = nn.MaxPool2d(2) #Maxpool layer 형성\n",
    "        self.fc1 = nn.Linear(320,100) \n",
    "        self.fc2 = nn.Linear(100,10) \n",
    "\n",
    "    # CNN의 forward path 지정\n",
    "  def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x))) # X -> conv1 -> maxpooling -> reLu\n",
    "        x = F.relu(self.mp(self.conv2(x))) # X -> conv2 -> maxpooling -> reLu\n",
    "        x = self.drop2D(x) # x -> dropout\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device) # ConvNet 인스턴스 생성후  아까 지정한 cpu, cuda device로 이동\n",
    "criterion = nn.CrossEntropyLoss().to(device) # nn.CrossEntropyLoss 인스턴스 생성 후 device로 이동\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # torch.optim.Adam 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\임지영\\AppData\\Local\\Temp\\ipykernel_15516\\2276327833.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1]  cost = 0.329658031\n",
      "[Epoch:    2]  cost = 0.111329406\n",
      "[Epoch:    3]  cost = 0.0847552493\n",
      "[Epoch:    4]  cost = 0.0729539767\n",
      "[Epoch:    5]  cost = 0.0650844425\n"
     ]
    }
   ],
   "source": [
    "# CNN 학습 \n",
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader: # iterate over trainig examples in mini-batches\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad() # set gradients to zero\n",
    "        hypothesis = model(data) # predicted output\n",
    "        cost = criterion(hypothesis, target) \n",
    "        cost.backward() # compute gradients of the model's parameters with respect to the loss\n",
    "        optimizer.step() \n",
    "        avg_cost += cost / len(train_loader) \n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\임지영\\AppData\\Local\\Temp\\ipykernel_15516\\2276327833.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  98.73 %\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "with torch.no_grad(): # disables gradient computation -> reduces memory usage\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data) # predicted output\n",
    "        preds = torch.max(out.data, 1)[1] \n",
    "        total += len(target) # update the total number of test examples\n",
    "        correct += (preds==target).sum().item() # update the number of correctly classified test examples\n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%') # prints test accuracy\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
